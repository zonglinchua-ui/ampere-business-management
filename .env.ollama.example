# LLM Configuration for Document Processing
# Choose your LLM provider: 'ollama', 'openai', or 'abacusai'
LLM_PROVIDER=ollama

# Ollama Configuration (if using local Ollama)
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3.1:8b

# Alternative models you can use with Ollama:
# - llama3.1:8b (recommended for general use)
# - llama3.1:70b (better accuracy, requires more resources)
# - mistral:7b (faster, good for simple tasks)
# - qwen2.5:14b (good for document understanding)

# OpenAI Configuration (if using OpenAI)
# LLM_PROVIDER=openai
# OPENAI_API_KEY=your_openai_api_key_here

# AbacusAI Configuration (if using AbacusAI)
# LLM_PROVIDER=abacusai
# ABACUSAI_API_KEY=your_abacusai_api_key_here
